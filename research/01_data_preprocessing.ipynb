{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbfc74e",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ded09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/pranta_2411ai09/dialogue_summ/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21bb1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/pranta_2411ai09/dialogue_summ/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/DATA/pranta_2411ai09/dialogue_summ/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load required model and tokenizer\n",
    "model_name = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b4323f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/DATA/pranta_2411ai09/DialogueSummarization/src'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750bf5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-26 09:57:04--  https://github.com/entbappy/Branching-tutorial/raw/master/summarizer-data.zip\n",
      "Resolving github.com (github.com)... 20.207.73.82\n",
      "Connecting to github.com (github.com)|20.207.73.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/entbappy/Branching-tutorial/master/summarizer-data.zip [following]\n",
      "--2025-09-26 09:57:04--  https://raw.githubusercontent.com/entbappy/Branching-tutorial/master/summarizer-data.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7903594 (7.5M) [application/zip]\n",
      "Saving to: ‘/DATA/pranta_2411ai09/DialogueSummarization/data/summarizer-data.zip’\n",
      "\n",
      "/DATA/pranta_2411ai 100%[===================>]   7.54M  41.7MB/s    in 0.2s    \n",
      "\n",
      "2025-09-26 09:57:05 (41.7 MB/s) - ‘/DATA/pranta_2411ai09/DialogueSummarization/data/summarizer-data.zip’ saved [7903594/7903594]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O /DATA/pranta_2411ai09/DialogueSummarization/data/summarizer-data.zip https://github.com/entbappy/Branching-tutorial/raw/master/summarizer-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ade8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /DATA/pranta_2411ai09/DialogueSummarization/data/summarizer-data.zip\n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum-test.csv  \n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum-train.csv  \n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum-validation.csv  \n",
      "   creating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/\n",
      " extracting: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/dataset_dict.json  \n",
      "   creating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/test/\n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/test/data-00000-of-00001.arrow  \n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/test/dataset_info.json  \n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/test/state.json  \n",
      "   creating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/train/\n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/train/data-00000-of-00001.arrow  \n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/train/dataset_info.json  \n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/train/state.json  \n",
      "   creating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/validation/\n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/validation/data-00000-of-00001.arrow  \n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/validation/dataset_info.json  \n",
      "  inflating: /DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset/validation/state.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip /DATA/pranta_2411ai09/DialogueSummarization/data/summarizer-data.zip -d /DATA/pranta_2411ai09/DialogueSummarization/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d76567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset_samsum = load_from_disk('/DATA/pranta_2411ai09/DialogueSummarization/data/samsum_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5265640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a21313",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed2f4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split lengths: [14732, 819, 818]\n",
      "Features: ['id', 'dialogue', 'summary']\n",
      "\n",
      "Dialogue:\n",
      "Eric: MACHINE!\n",
      "Rob: That's so gr8!\n",
      "Eric: I know! And shows how Americans see Russian ;)\n",
      "Rob: And it's really funny!\n",
      "Eric: I know! I especially like the train part!\n",
      "Rob: Hahaha! No one talks to the machine like that!\n",
      "Eric: Is this his only stand-up?\n",
      "Rob: Idk. I'll check.\n",
      "Eric: Sure.\n",
      "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
      "Eric: Gr8! I'll watch them now!\n",
      "Rob: Me too!\n",
      "Eric: MACHINE!\n",
      "Rob: MACHINE!\n",
      "Eric: TTYL?\n",
      "Rob: Sure :)\n",
      "\n",
      "Summary:\n",
      "Eric and Rob are going to watch a stand-up on youtube.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Split lengths: {split_lengths}\")\n",
    "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\nDialogue:\")\n",
    "\n",
    "print(dataset_samsum[\"test\"][1][\"dialogue\"])\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "\n",
    "print(dataset_samsum[\"test\"][1][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f92711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n",
    "        \n",
    "    return {\n",
    "        'input_ids' : input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9d5aa",
   "metadata": {},
   "source": [
    "#### Convert raw dataset into the format expected by your model for supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a069096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]/DATA/pranta_2411ai09/dialogue_summ/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 14732/14732 [00:02<00:00, 5423.77 examples/s]\n",
      "Map: 100%|██████████| 819/819 [00:00<00:00, 6606.93 examples/s]\n",
      "Map: 100%|██████████| 818/818 [00:00<00:00, 6900.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c867e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 14732\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a69eef8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13728867',\n",
       " 'dialogue': 'Olivia: Who are you voting for in this election? \\r\\nOliver: Liberals as always.\\r\\nOlivia: Me too!!\\r\\nOliver: Great',\n",
       " 'summary': 'Olivia and Olivier are voting for liberals in this election. ',\n",
       " 'input_ids': [18038,\n",
       "  151,\n",
       "  2632,\n",
       "  127,\n",
       "  119,\n",
       "  6228,\n",
       "  118,\n",
       "  115,\n",
       "  136,\n",
       "  2974,\n",
       "  152,\n",
       "  10463,\n",
       "  151,\n",
       "  35884,\n",
       "  130,\n",
       "  329,\n",
       "  107,\n",
       "  18038,\n",
       "  151,\n",
       "  2587,\n",
       "  314,\n",
       "  1242,\n",
       "  10463,\n",
       "  151,\n",
       "  1509,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [18038, 111, 34296, 127, 6228, 118, 33195, 115, 136, 2974, 107, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d8c73ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13729565',\n",
       " 'dialogue': \"Eric: MACHINE!\\r\\nRob: That's so gr8!\\r\\nEric: I know! And shows how Americans see Russian ;)\\r\\nRob: And it's really funny!\\r\\nEric: I know! I especially like the train part!\\r\\nRob: Hahaha! No one talks to the machine like that!\\r\\nEric: Is this his only stand-up?\\r\\nRob: Idk. I'll check.\\r\\nEric: Sure.\\r\\nRob: Turns out no! There are some of his stand-ups on youtube.\\r\\nEric: Gr8! I'll watch them now!\\r\\nRob: Me too!\\r\\nEric: MACHINE!\\r\\nRob: MACHINE!\\r\\nEric: TTYL?\\r\\nRob: Sure :)\",\n",
       " 'summary': 'Eric and Rob are going to watch a stand-up on youtube.',\n",
       " 'input_ids': [6303,\n",
       "  151,\n",
       "  60662,\n",
       "  147,\n",
       "  7374,\n",
       "  151,\n",
       "  485,\n",
       "  131,\n",
       "  116,\n",
       "  167,\n",
       "  17050,\n",
       "  2000,\n",
       "  147,\n",
       "  6303,\n",
       "  151,\n",
       "  125,\n",
       "  235,\n",
       "  147,\n",
       "  325,\n",
       "  939,\n",
       "  199,\n",
       "  3361,\n",
       "  236,\n",
       "  3058,\n",
       "  26408,\n",
       "  7374,\n",
       "  151,\n",
       "  325,\n",
       "  126,\n",
       "  131,\n",
       "  116,\n",
       "  288,\n",
       "  3765,\n",
       "  147,\n",
       "  6303,\n",
       "  151,\n",
       "  125,\n",
       "  235,\n",
       "  147,\n",
       "  125,\n",
       "  704,\n",
       "  172,\n",
       "  109,\n",
       "  1976,\n",
       "  297,\n",
       "  147,\n",
       "  7374,\n",
       "  151,\n",
       "  110,\n",
       "  52228,\n",
       "  147,\n",
       "  566,\n",
       "  156,\n",
       "  3935,\n",
       "  112,\n",
       "  109,\n",
       "  1157,\n",
       "  172,\n",
       "  120,\n",
       "  147,\n",
       "  6303,\n",
       "  151,\n",
       "  125,\n",
       "  116,\n",
       "  136,\n",
       "  169,\n",
       "  209,\n",
       "  1281,\n",
       "  121,\n",
       "  768,\n",
       "  152,\n",
       "  7374,\n",
       "  151,\n",
       "  125,\n",
       "  31664,\n",
       "  107,\n",
       "  125,\n",
       "  131,\n",
       "  267,\n",
       "  553,\n",
       "  107,\n",
       "  6303,\n",
       "  151,\n",
       "  7435,\n",
       "  107,\n",
       "  7374,\n",
       "  151,\n",
       "  24831,\n",
       "  165,\n",
       "  220,\n",
       "  147,\n",
       "  353,\n",
       "  127,\n",
       "  181,\n",
       "  113,\n",
       "  169,\n",
       "  1281,\n",
       "  121,\n",
       "  5151,\n",
       "  124,\n",
       "  11909,\n",
       "  107,\n",
       "  6303,\n",
       "  151,\n",
       "  12550,\n",
       "  2000,\n",
       "  147,\n",
       "  125,\n",
       "  131,\n",
       "  267,\n",
       "  1183,\n",
       "  183,\n",
       "  239,\n",
       "  147,\n",
       "  7374,\n",
       "  151,\n",
       "  2587,\n",
       "  314,\n",
       "  147,\n",
       "  6303,\n",
       "  151,\n",
       "  60662,\n",
       "  147,\n",
       "  7374,\n",
       "  151,\n",
       "  60662,\n",
       "  147,\n",
       "  6303,\n",
       "  151,\n",
       "  21216,\n",
       "  35219,\n",
       "  152,\n",
       "  7374,\n",
       "  151,\n",
       "  7435,\n",
       "  8537,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [6303,\n",
       "  111,\n",
       "  7374,\n",
       "  127,\n",
       "  313,\n",
       "  112,\n",
       "  1183,\n",
       "  114,\n",
       "  1281,\n",
       "  121,\n",
       "  768,\n",
       "  124,\n",
       "  11909,\n",
       "  107,\n",
       "  1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt['test'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ff1862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 14732/14732 [00:00<00:00, 285489.48 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 819/819 [00:00<00:00, 89349.61 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 818/818 [00:00<00:00, 85956.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Save the processed dataset to the data folder\n",
    "save_path = '/DATA/pranta_2411ai09/DialogueSummarization/data/samsum_pt_dataset'\n",
    "dataset_samsum_pt.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a78c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
